# Main training script settings
training_settings:
  n_episodes: 10000
  max_t_per_episode: 700 # This will be used for impatience penalty normalization
  eps_start: 1.0
  eps_end: 0.01
  eps_decay: 0.999
  load_checkpoint: false
  checkpoint_to_load: "bug_agent_ep1000.pth"
  save_checkpoint_every: 500
  final_model_name: "bug_agent_final.pth"
  render_each_n_episodes: 0

# DQN Agent hyperparameters
agent_hyperparameters:
  buffer_size: 100000
  batch_size: 64
  gamma: 0.99
  tau: 0.001
  lr: 0.0005
  update_every: 4
  target_update_every: 100

# Training Environment (BugSkillTrainingEnv) settings
environment_settings:
  skill_params: # bug_x_rl_move_speed, etc. will be here
    bug_x_rl_move_speed: 0.035
    bug_y_rl_move_speed: 0.025
    base_y_speed: 0.00 # Agent must learn Y movement
    duration_ms: 8000
    bug_visual_radius_norm_factor: 0.0375
    max_steps_for_impatience: 700 # Should be set by train.py from training_settings.max_t_per_episode

    # ⭐️ 新增：蟲的初始位置隨機範圍 (假設蟲從下方區域出現，攻擊上方 Y=0 的目標)
    initial_bug_x_min: 0.05
    initial_bug_x_max: 0.95
    initial_bug_y_min: 0.3  # Y 軸較大值表示更靠近螢幕底部
    initial_bug_y_max: 0.9

  opponent_ai_settings:
    use_dynamic_opponent: true
    # ⭐️ 修改：model_filename 現在只包含檔案名稱
    model_filename: "level2.pth" # 或者你想要預設載入的特定模型檔案名
    # ⭐️ 新增：指定對手模型存放的資料夾
    opponent_model_directory: "opponent_models/" # 相對於 soul_eater_trainer 主目錄的路徑
    paddle_move_speed: 0.03

  reward_shaping:
    # 1. 基礎獎勵/懲罰
    step_penalty: 0.0                # 每一步的基礎懲罰 (鼓勵效率)
    score_reward: 15.0                 # 成功得分的獎勵
    hit_paddle_penalty: -5.0           # 撞到目標板子的懲罰 (這是指蟲撞到板子而結束)
    duration_expired_penalty: -15.0     # 技能時間到但未得分/撞板的懲罰

    # 2. 「布朗運動」/ 移動獎勵 (避免靜止)
    enable_movement_reward: true       # 是否啟用移動獎勵
    movement_reward_factor: 0.5      # 每次有效移動給予的獎勵值 (正值)

    # 3. 「急躁」衝鋒懲罰 (隨時間遞增)
    # 懲罰公式: -(m + n * (current_step_in_episode / max_steps_for_impatience)^k)
    enable_impatience_penalty: true    # 是否啟用急躁懲罰
    impatience_penalty_m: 0.1        # 基礎懲罰值 (m)
    impatience_penalty_n: 0.1         # 時間遞增因子 (n)
    impatience_penalty_k: 3.0          # 時間指數 (k)

    # 4. 遠離板子 / 靠近得分線 (細化)
    #    目標板子在上方 (y=0 附近是其板面，y更小是得分區/底線)
    #    蟲的 Y 座標 (self.mock_env_for_skill.ball_y)

    # 4a. 盡可能跑到底線 (靠近得分線 Y=0)
    enable_baseline_progress_reward: true # 是否啟用靠近底線獎勵
    baseline_progress_reward_factor: 0.3  # 蟲每向底線 (Y軸變小) 移動的獎勵因子 (正值)
                                          # (獎勵 = factor * (previous_y - current_y))

    # 4b. 盡可能遠離板子 (避免撞擊上方板面)
    #     板子表面在 Y = 0 到 Y = paddle_height_normalized 之間
    enable_paddle_avoidance_penalty: true # 是否啟用遠離板子懲罰
    paddle_avoidance_penalty_factor: -0.2 # 當蟲靠近板子時的懲罰因子 (負值)
    paddle_danger_zone_y_threshold: 0.15  # (正規化單位) 從板子"背面"(離蟲初始位置遠的一面)向上延伸的危險區域深度
                                          # 蟲的Y (ball_y) 與板子最下緣 (paddle_height_normalized) 的距離
                                          # 若 ball_y < (paddle_height_normalized + threshold), 則可能懲罰
                                          # 例如, paddle_height=0.025, threshold=0.15. Danger if ball_y < 0.175